---
title: "Distributed Learning of Multi-Joint Single Robot with Resilience Guarantee"
excerpt: "In order to satisfy the need for large-scale, decentralized and multi-agent collaborative work in the future, and to realize safe operation in the process of fully autonomous/human-computer interaction, multi-robot reinforcement learning has gradually become a research hotspot in the field of machine learning (ML). There has been an intensive and in-depth research on decentralized and centralized learning, but it is still mainly based on collaborative learning between multiple robots. In this project, we present a clever extension to the single-agent robot, and propose a decentralized multi-agent reinforcement learning method (D-MARL) for a multi-part single robot body by constructing a graph network. In addition, the ability of safe and robust autonomous collaborative learning is the key to the degree of intelligence of multi-robots and to decide whether they can get out of the laboratory and move towards real-life applications. The question of how to effectively explain the nature of the learning process is the bottleneck of the current ML. To this end, this article starts from the perspective of resilience guarantee and gives the design of the critic function based on the Lyapunov stability theory. Finally, we compared and verified the proposed method in a Multi-Agent Mujoco environment, and its resilience ability was evaluated under multi-scale constant impulse disturbance and mass loss disturbance. The results can prove that the D-MARL method proposed in this project presents a significant improvement in the learning rate and anti-interference transfer ability compared with the multi-agent soft actor-critic (MASAC) and multi-agent deep deterministic policy gradient (MADDPG).<img src='/images/Project04.png'>"
collection: portfolio
---
